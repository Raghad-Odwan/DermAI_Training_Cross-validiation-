{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raghad-Odwan/DermAI_Training/blob/main/DermAI_Model_Training_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM9j1mMPmK1C"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BZSwgpySG-f",
        "outputId": "46cd8b6b-9ca8-4571-d900-96606e12b294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtSwYn7MR8jT",
        "outputId": "6bb25346-cf7b-4066-bf6e-323d8330f703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VCfgt1ggPLpH",
        "outputId": "33dd8e75-279e-4b0a-d0ef-dd3204f7d898"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "    console.log(\"Preventing Colab timeout\");\n",
              "    document.querySelector(\"colab-toolbar-button#connect\").click();\n",
              "}\n",
              "setInterval(ClickConnect, 60000)\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%javascript\n",
        "function ClickConnect(){\n",
        "    console.log(\"Preventing Colab timeout\");\n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click();\n",
        "}\n",
        "setInterval(ClickConnect, 60000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujA-N-lvmNt_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJqf6nCNSK99"
      },
      "source": [
        "# **DermAI_AI_Model_Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qb13R6y4OWW"
      },
      "source": [
        "## About this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvegU7jsUFOa"
      },
      "source": [
        "This Google Colab notebook has been prepared for the preparation and training of a machine learning model specialized in skin cancer detection.\n",
        "The model performs binary classification of skin lesion images into two categories: Benign and Malignant.\n",
        "\n",
        "\n",
        "### Dataset Source\n",
        "\n",
        "The dataset used in this project was collected from the following sources:\n",
        "(                  _____                )\n",
        "\n",
        "The dataset contains approximately 13,249 benign and 6,211 malignant images, providing a total of around 19,460 samples used for training, validation, and testing.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Notebook Structure\n",
        "\n",
        "This notebook is organized into three main sections:\n",
        "\n",
        "**-Data Loading, Verification, and Preprocessing**\n",
        "\n",
        "This section focuses on importing the dataset, verifying its structure, cleaning inconsistencies, and performing Exploratory Data Analysis (EDA).\n",
        "Steps include resizing, normalization, data augmentation, and splitting the dataset into training, validation, and testing subsets.\n",
        "\n",
        "**-Model Training and Evaluation**\n",
        "\n",
        "In this section, a machine learning model is implemented and trained for skin lesion classification.\n",
        "The process includes model configuration, training, and performance evaluation using metrics such as accuracy, precision, recall, and F1-score.\n",
        "Optimization methods are also applied to ensure stable and efficient training.\n",
        "\n",
        "**-Result Interpretation and Visualization**\n",
        "\n",
        "This part is dedicated to analyzing the model’s predictions and interpreting its decision-making process using Grad-CAM and other visualization tools.\n",
        "It highlights how the model distinguishes between benign and malignant lesions, providing insights into reliability and interpretability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PuzGd2ij6kK"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Note: This notebook represents a core component of the DermAI Graduation Project at Palestine Technical University – Kadoorie.\n",
        "It aims to demonstrate the end-to-end process of building an intelligent, interpretable, and efficient system for skin cancer classification, contributing to early detection and supporting clinical decision-making.**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlNwr0kGmi-h"
      },
      "source": [
        "## **Part One: Dataset Preparation & Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MtslpsqEsU88"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VQSvLBtsbCJ",
        "outputId": "86831bbd-472e-4409-c304-e84eb02b7a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base directory: /content/drive/MyDrive/Dataset/Dataset\n",
            "benign: 13291 files\n",
            "malignant: 6210 files\n"
          ]
        }
      ],
      "source": [
        "# Define main dataset path\n",
        "base_dir = \"/content/drive/MyDrive/Dataset/Dataset\"\n",
        "folders = [\"benign\", \"malignant\"]\n",
        "\n",
        "print(\"Base directory:\", base_dir)\n",
        "for folder in folders:\n",
        "    path = os.path.join(base_dir, folder)\n",
        "    print(f\"{folder}: {len(os.listdir(path))} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ8eTjKisdq6",
        "outputId": "78309b56-067f-48ff-c371-80aac54d27eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate/Corrupted folder created at: /content/drive/MyDrive/Dataset/Dataset/duplicates_or_corrupted\n"
          ]
        }
      ],
      "source": [
        "# Create a folder for problematic images\n",
        "dup_dir = os.path.join(base_dir, \"duplicates_or_corrupted\")\n",
        "os.makedirs(dup_dir, exist_ok=True)\n",
        "print(\"Duplicate/Corrupted folder created at:\", dup_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO9lRiMgsjp1",
        "outputId": "a0d09921-94b0-404b-9a35-f46d91ce93bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning benign (13291 images)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking benign:   1%|          | 103/13291 [00:42<1:21:04,  2.71it/s]"
          ]
        }
      ],
      "source": [
        "# Define an image cleaning class\n",
        "class ImageCleaner:\n",
        "    def __init__(self, base_path):\n",
        "        self.base_path = Path(base_path)\n",
        "        self.folders_to_check = ['benign', 'malignant']\n",
        "        self.problem_folder = self.base_path / 'duplicates_or_corrupted'\n",
        "        self.problem_folder.mkdir(exist_ok=True)\n",
        "        self.stats = {'total_checked': 0, 'corrupted': 0, 'duplicates': 0, 'low_quality': 0, 'healthy': 0}\n",
        "        self.image_hashes = defaultdict(list)\n",
        "\n",
        "    def calculate_hash(self, image_path):\n",
        "        import hashlib\n",
        "        try:\n",
        "            hasher = hashlib.md5()\n",
        "            with open(image_path, 'rb') as f:\n",
        "                buf = f.read()\n",
        "                hasher.update(buf)\n",
        "            return hasher.hexdigest()\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def is_image_corrupted(self, image_path):\n",
        "        try:\n",
        "            with Image.open(image_path) as img:\n",
        "                img.verify()\n",
        "            return False\n",
        "        except:\n",
        "            return True\n",
        "\n",
        "    def check_image_quality(self, image_path, min_width=50, min_height=50):\n",
        "        try:\n",
        "            with Image.open(image_path) as img:\n",
        "                width, height = img.size\n",
        "                if width < min_width or height < min_height:\n",
        "                    return False\n",
        "                if os.path.getsize(image_path) < 1000:\n",
        "                    return False\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def move_to_problem_folder(self, image_path):\n",
        "        try:\n",
        "            dest_subfolder = self.problem_folder / image_path.parent.name\n",
        "            dest_subfolder.mkdir(exist_ok=True)\n",
        "            shutil.move(str(image_path), str(dest_subfolder / image_path.name))\n",
        "        except Exception as e:\n",
        "            print(f\"Error moving {image_path.name}: {e}\")\n",
        "\n",
        "    def clean_folder(self, folder_name):\n",
        "        folder_path = self.base_path / folder_name\n",
        "        image_exts = ['.jpg', '.jpeg', '.png']\n",
        "        images = [f for f in folder_path.iterdir() if f.suffix.lower() in image_exts]\n",
        "        print(f\"Cleaning {folder_name} ({len(images)} images)...\")\n",
        "\n",
        "        for img_path in tqdm(images, desc=f\"Checking {folder_name}\"):\n",
        "            self.stats['total_checked'] += 1\n",
        "            if self.is_image_corrupted(img_path):\n",
        "                self.move_to_problem_folder(img_path)\n",
        "                self.stats['corrupted'] += 1\n",
        "                continue\n",
        "            if not self.check_image_quality(img_path):\n",
        "                self.move_to_problem_folder(img_path)\n",
        "                self.stats['low_quality'] += 1\n",
        "                continue\n",
        "            img_hash = self.calculate_hash(img_path)\n",
        "            if img_hash in self.image_hashes:\n",
        "                self.move_to_problem_folder(img_path)\n",
        "                self.stats['duplicates'] += 1\n",
        "            else:\n",
        "                self.image_hashes[img_hash].append(str(img_path))\n",
        "                self.stats['healthy'] += 1\n",
        "\n",
        "    def clean_all(self):\n",
        "        for folder in self.folders_to_check:\n",
        "            self.clean_folder(folder)\n",
        "        print(\"\\nCleaning Summary:\")\n",
        "        for k, v in self.stats.items():\n",
        "            print(f\"{k}: {v}\")\n",
        "\n",
        "# Run the cleaning process\n",
        "cleaner = ImageCleaner(base_dir)\n",
        "cleaner.clean_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Aa5ODGQs6NI"
      },
      "outputs": [],
      "source": [
        "# Visualize class distribution\n",
        "count_benign = len(os.listdir(os.path.join(base_dir, \"benign\")))\n",
        "count_malignant = len(os.listdir(os.path.join(base_dir, \"malignant\")))\n",
        "plt.bar([\"Benign\", \"Malignant\"], [count_benign, count_malignant])\n",
        "plt.title(\"Class Distribution After Cleaning\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuesJ_ALs8Cq"
      },
      "outputs": [],
      "source": [
        "# Resize all images to (224x224)\n",
        "IMG_SIZE = (224, 224)\n",
        "for cat in folders:\n",
        "    src_dir = os.path.join(base_dir, cat)\n",
        "    files = os.listdir(src_dir)\n",
        "    for fname in tqdm(files, desc=f\"Resizing {cat}\"):\n",
        "        path = os.path.join(src_dir, fname)\n",
        "        try:\n",
        "            img = cv2.imread(path)\n",
        "            if img is None: continue\n",
        "            resized = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
        "            cv2.imwrite(path, resized)\n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXqP3MmYtJYu"
      },
      "outputs": [],
      "source": [
        "# Split dataset (70% train, 15% val, 15% test)\n",
        "split_dir = \"/content/ai/Dataset_split\"\n",
        "os.makedirs(split_dir, exist_ok=True)\n",
        "\n",
        "rows = []\n",
        "for label in folders:\n",
        "    path = os.path.join(base_dir, label)\n",
        "    for fname in os.listdir(path):\n",
        "        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            rows.append({'path': os.path.join(path, fname), 'label': label})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "train_temp, test = train_test_split(df, test_size=0.15, stratify=df['label'], random_state=42)\n",
        "train, val = train_test_split(train_temp, test_size=0.1765, stratify=train_temp['label'], random_state=42)\n",
        "\n",
        "for subset in ['train', 'val', 'test']:\n",
        "    for label in folders:\n",
        "        os.makedirs(os.path.join(split_dir, subset, label), exist_ok=True)\n",
        "\n",
        "def copy_images(df_subset, subset_name):\n",
        "    for _, row in tqdm(df_subset.iterrows(), total=len(df_subset), desc=f\"Copying {subset_name}\"):\n",
        "        dest = os.path.join(split_dir, subset_name, row['label'], os.path.basename(row['path']))\n",
        "        shutil.copy2(row['path'], dest)\n",
        "\n",
        "copy_images(train, \"train\")\n",
        "copy_images(val, \"val\")\n",
        "copy_images(test, \"test\")\n",
        "\n",
        "print(f\"\\nDataset split completed successfully!\")\n",
        "print(f\"Train: {len(train)} | Val: {len(val)} | Test: {len(test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BrWAksE227X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "####  Build DataFrame & Quick Integrity Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARx5owga3By7"
      },
      "outputs": [],
      "source": [
        "# Count the number of image files in each class folder (benign and malignant)\n",
        "# This function walks through all subdirectories and counts only valid image files.\n",
        "import os, sys, traceback\n",
        "base_path = \"/content/drive/MyDrive/Dataset/Dataset\"\n",
        "\n",
        "def count_images_in_folder(folder):\n",
        "    exts = ('.jpg','.jpeg','.png','.bmp')\n",
        "    cnt = 0\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for f in files:\n",
        "            if f.lower().endswith(exts):\n",
        "                cnt += 1\n",
        "    return cnt\n",
        "\n",
        "for cls in ['benign','malignant']:\n",
        "    p = os.path.join(base_path, cls)\n",
        "    if not os.path.exists(p):\n",
        "        print(f\" WARNING: folder not found: {p}\")\n",
        "    else:\n",
        "        print(f\"{cls}: {count_images_in_folder(p):,} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z8QjeKr30K-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "# build dataframe (paths + labels)\n",
        "rows=[]\n",
        "exts = ('.jpg','.jpeg','.png','.bmp')\n",
        "for cls in ['benign','malignant']:\n",
        "    folder = os.path.join(base_path, cls)\n",
        "    if not os.path.exists(folder):\n",
        "        continue\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for fname in files:\n",
        "            if fname.lower().endswith(exts):\n",
        "                rows.append({'path': os.path.join(root, fname), 'label': cls})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df['label_idx'] = df['label'].map({'benign':0, 'malignant':1})\n",
        "print(\"Total samples:\", len(df))\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dho8-d694E6j"
      },
      "outputs": [],
      "source": [
        "#  quick corrupted-files check (lightweight, may take time if dataset big)\n",
        "#  try to open the first N images from each class to detect obvious corruption\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "def check_samples(df, n_per_class=20):\n",
        "    corrupted = []\n",
        "    for cls in df['label'].unique():\n",
        "        paths = df[df['label']==cls]['path'].tolist()\n",
        "        sample_paths = random.sample(paths, min(n_per_class, len(paths)))\n",
        "        for p in sample_paths:\n",
        "            try:\n",
        "                img = Image.open(p)\n",
        "                img.verify()\n",
        "            except Exception as e:\n",
        "                corrupted.append((p, str(e)))\n",
        "    return corrupted\n",
        "\n",
        "corrupted_examples = check_samples(df, n_per_class=30)\n",
        "if corrupted_examples:\n",
        "    print(\" Found corrupted or unreadable sample(s):\", len(corrupted_examples))\n",
        "    for p,err in corrupted_examples[:5]:\n",
        "        print(\"-\", p, \"=>\", err)\n",
        "else:\n",
        "    print(\" Quick corrupted-sample check passed successfully (no issues in sampled files).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX7JGCIv4dht"
      },
      "outputs": [],
      "source": [
        "# Save metadata CSV\n",
        "out_csv = \"/content/drive/MyDrive/ai/data/df_metadata.csv\"\n",
        "os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
        "df.to_csv(out_csv, index=False)\n",
        "print(\" Metadata saved to:\", out_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X8S6Okp6JrA"
      },
      "outputs": [],
      "source": [
        "display(df.head(10))\n",
        "print(\"\\nCounts (sanity):\")\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY4uoFC17E4w"
      },
      "outputs": [],
      "source": [
        "# Quick test reading data\n",
        "# Randomly load and display one sample image from the dataset\n",
        "# to verify that image paths are correct and preprocessing worked properly.\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample = random.choice(df['path'].tolist())\n",
        "img = image.load_img(sample, target_size=(224,224))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(sample.split('/')[-2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exo-cHl6Ce_n"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj7gChfDChNO"
      },
      "source": [
        "## **Part Two: Model Training and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2.1: Cross_Valditon**"
      ],
      "metadata": {
        "id": "sU0d1NdYUery"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8hnWIppDKDF"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os, math, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    auc\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "\n",
        "# Parameters\n",
        "# Defines image size, batch size, epochs, and model saving directory\n",
        "DRIVE_BASE = \"/content/drive/MyDrive\"\n",
        "DF_PATH = os.path.join(DRIVE_BASE, \"ai/data/df_metadata.csv\")\n",
        "MODELS_DIR = os.path.join(DRIVE_BASE, \"DermAI_models_resnet\")\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 30\n",
        "N_FOLDS = 3\n",
        "RANDOM_STATE = 42\n",
        "VERBOSE = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3NIU_7RESJF"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_emNvBXnEcr0"
      },
      "outputs": [],
      "source": [
        "# Read & Inspect Metadata\n",
        "meta_csv = \"/content/drive/MyDrive/ai/data/df_metadata.csv\"\n",
        "df = pd.read_csv(meta_csv)\n",
        "\n",
        "print(\"Loaded df:\", meta_csv)\n",
        "print(\"Total samples:\", len(df))\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "display(df.head(10))\n",
        "\n",
        "# Prepare X and y for training\n",
        "X = df['path'].values\n",
        "y = df['label_idx'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5N0CPqKE9Ms"
      },
      "source": [
        "**Data Generators**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNTmqGopho8M"
      },
      "source": [
        "* Prepare image generators for training and validation.\n",
        "* Training generator applies data augmentation to improve model generalization, while validation generator only rescales pixel values.\n",
        "* ralies moderate augmentation; validation only rescales.ining generator app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKyxJfbVFAhQ"
      },
      "outputs": [],
      "source": [
        "# Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    brightness_range=[0.9, 1.1]\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYJjSx-Ky7yh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsmmzHpuy93r"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMDmGUZ8Fy7q"
      },
      "source": [
        "**Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkR6aL9QFxkH"
      },
      "outputs": [],
      "source": [
        "# Build ResNet50 binary classifier with fine-tuning of the last N layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_resnet_binary(input_shape=(224,224,3), unfreeze_last_n=60):\n",
        "    # Load base ResNet50 without top layers\n",
        "    base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze all layers\n",
        "    for layer in base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Unfreeze last N layers (except BatchNorm)\n",
        "    for layer in base.layers[-unfreeze_last_n:]:\n",
        "        if \"batch_normalization\" in layer.name:\n",
        "            layer.trainable = False\n",
        "        else:\n",
        "            layer.trainable = True\n",
        "\n",
        "    # Classification head\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs=base.input, outputs=outputs)\n",
        "\n",
        "    # Correct Adam optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "    # Compile\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgzHe6mtGMfF"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiAGg0FDdM15"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCiRJ5_UxN9Y"
      },
      "outputs": [],
      "source": [
        "# Utility Functions for Dataset Loading & Preprocessing\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "def compute_weights(y_array):\n",
        "    classes = np.unique(y_array)\n",
        "    cw = compute_class_weight('balanced', classes=classes, y=y_array)\n",
        "    return {int(c): float(w) for c,w in zip(classes, cw)}\n",
        "\n",
        "def print_generator_info(gen, name=\"generator\"):\n",
        "    print(f\"{name} class_indices:\", getattr(gen, 'class_indices', None))\n",
        "    if hasattr(gen, 'classes'):\n",
        "        u,c = np.unique(gen.classes, return_counts=True)\n",
        "        print(f\"{name} counts:\", dict(zip(u,c)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuNYik4jNowX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot (Accuracy/Loss, Confusion Matrix, ROC Curve) for each flods and save it"
      ],
      "metadata": {
        "id": "BHQ2SW2--JKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plots_dir = \"/content/drive/MyDrive/DermAI_Training_resluts_plots\"\n",
        "os.makedirs(plots_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "bBB3zMHN83kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curves(history, fold_no, save_dir=plots_dir):\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title(f'Accuracy Curve – Fold {fold_no}')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'Loss Curve – Fold {fold_no}')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "\n",
        "    # save\n",
        "    save_path = os.path.join(save_dir, f\"fold_{fold_no}_accuracy_loss.png\")\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OogEupr789z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion_matrix\n",
        "def plot_confusion_matrix(true, preds, fold_no, save_dir=plots_dir):\n",
        "    cm = confusion_matrix(true, preds)\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix – Fold {fold_no}')\n",
        "    plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
        "\n",
        "    save_path = os.path.join(save_dir, f\"fold_{fold_no}_confusion_matrix.png\")\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "unowgOLE9FJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC Curve\n",
        "def plot_roc(true, prob, fold_no, save_dir=plots_dir):\n",
        "    fpr, tpr, _ = roc_curve(true, prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
        "    plt.plot([0,1], [0,1], linestyle='--')\n",
        "    plt.title(f'ROC Curve – Fold {fold_no}')\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.legend()\n",
        "\n",
        "    save_path = os.path.join(save_dir, f\"fold_{fold_no}_roc_curve.png\")\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "d3dTGK2o9KHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "78XFyJIq82aU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epO8C1qSNqN1"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8hl0uH_ho8Z"
      },
      "source": [
        "For each fold:\n",
        "*  Split data into training and validation subsets while preserving class balance.\n",
        "*   Build and train a ResNet50 model on the training subset.\n",
        "* Evaluate model performance on the validation subset (Accuracy, Precision, Recall, F1).\n",
        "* Save best model weights and record per-fold metrics.\n",
        "And after that Results from all folds are stored in 'fold_metrics' for later summary and analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJidgjQUGN7n"
      },
      "outputs": [],
      "source": [
        "import math, gc, os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/ai/data/df_metadata.csv')\n",
        "df_cv = df.copy()\n",
        "\n",
        "X = df_cv['path'].values\n",
        "y = df_cv['label_idx'].values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "splits = list(skf.split(X, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY05V3Zpv2d8"
      },
      "source": [
        "##### Fold 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrH4kmMFv1cy"
      },
      "outputs": [],
      "source": [
        "# Fold 1\n",
        "fold_no = 1\n",
        "\n",
        "# Data split\n",
        "train_idx, val_idx = splits[0]\n",
        "train_df = pd.DataFrame({'path': X[train_idx], 'label_idx': y[train_idx]})\n",
        "val_df   = pd.DataFrame({'path': X[val_idx],   'label_idx': y[val_idx]})\n",
        "\n",
        "class_weight = compute_weights(train_df['label_idx'].values)\n",
        "print(\"class_weight:\", class_weight)\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    train_df, x_col='path', y_col='label_idx',\n",
        "    target_size=IMG_SIZE, class_mode='raw',\n",
        "    batch_size=BATCH_SIZE, shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_dataframe(\n",
        "    val_df, x_col='path', y_col='label_idx',\n",
        "    target_size=IMG_SIZE, class_mode='raw',\n",
        "    batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "print_generator_info(train_gen, \"train_gen\")\n",
        "print_generator_info(val_gen, \"val_gen\")\n",
        "\n",
        "\n",
        "# Build Model\n",
        "model = build_resnet_binary(\n",
        "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "    unfreeze_last_n=40\n",
        ")\n",
        "\n",
        "\n",
        "# Callbacks\n",
        "ckpt_path = os.path.join(MODELS_DIR, f\"best_resnet_fold{fold_no}.keras\")\n",
        "csv_log_path = os.path.join(MODELS_DIR, f\"training_log_fold{fold_no}.csv\")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    CSVLogger(csv_log_path)\n",
        "]\n",
        "\n",
        "steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)\n",
        "val_steps = math.ceil(len(val_df) / BATCH_SIZE)\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=val_steps,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks,\n",
        "    verbose=VERBOSE\n",
        ")\n",
        "\n",
        "\n",
        "# Load Best Model\n",
        "best = tf.keras.models.load_model(ckpt_path)\n",
        "\n",
        "val_gen_eval = val_datagen.flow_from_dataframe(\n",
        "    val_df, x_col='path', y_col='label_idx',\n",
        "    target_size=IMG_SIZE, class_mode='raw',\n",
        "    batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "preds_prob = best.predict(val_gen_eval, steps=val_steps, verbose=VERBOSE)\n",
        "preds = (preds_prob.ravel() > 0.5).astype(int)\n",
        "true = val_df['label_idx'].values[:len(preds)]\n",
        "\n",
        "acc  = accuracy_score(true, preds)\n",
        "prec = precision_score(true, preds, zero_division=0)\n",
        "rec  = recall_score(true, preds, zero_division=0)\n",
        "f1   = f1_score(true, preds, zero_division=0)\n",
        "\n",
        "print(f\"Fold {fold_no} -> acc:{acc:.4f}, prec:{prec:.4f}, rec:{rec:.4f}, f1:{f1:.4f}\")\n",
        "print(classification_report(true, preds, target_names=['benign','malignant'], zero_division=0))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(true, preds))\n",
        "\n",
        "#  Visualization for this Fold\n",
        "plot_training_curves(history, fold_no)\n",
        "plot_confusion_matrix(true, preds, fold_no)\n",
        "plot_roc(true, preds_prob.ravel(), fold_no)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd9-IVpUwMle"
      },
      "source": [
        "##### Fold 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zIWd4ozwFnb"
      },
      "outputs": [],
      "source": [
        "# Fold 2\n",
        "fold_no = 2\n",
        "\n",
        "# Data split\n",
        "train_idx, val_idx = splits[1]\n",
        "train_df = pd.DataFrame({'path': X[train_idx], 'label_idx': y[train_idx]})\n",
        "val_df   = pd.DataFrame({'path': X[val_idx],   'label_idx': y[val_idx]})\n",
        "\n",
        "class_weight = compute_weights(train_df['label_idx'].values)\n",
        "print(\"class_weight:\", class_weight)\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    train_df, x_col='path', y_col='label_idx',\n",
        "    target_size=IMG_SIZE, class_mode='raw',\n",
        "    batch_size=BATCH_SIZE, shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_dataframe(\n",
        "    val_df, x_col='path', y_col='label_idx',\n",
        "    target_size=IMG_SIZE, class_mode='raw',\n",
        "    batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "print_generator_info(train_gen, \"train_gen\")\n",
        "print_generator_info(val_gen, \"val_gen\")\n",
        "\n",
        "\n",
        "# Build Model\n",
        "model = build_resnet_binary(\n",
        "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "    unfreeze_last_n=40\n",
        ")\n",
        "\n",
        "\n",
        "# Callbacks\n",
        "ckpt_path = os.path.join(MODELS_DIR, f\"best_resnet_fold{fold_no}.keras\")\n",
        "csv_log_path = os.path.join(MODELS_DIR, f\"training_log_fold{fold_no}.csv\")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    CSVLogger(csv_log_path)\n",
        "]\n",
        "\n",
        "steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)\n",
        "val_steps = math.ceil(len(val_df) / BATCH_SIZE)\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=val_steps,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks,\n",
        "    verbose=VERBOSE\n",
        ")\n",
        "\n",
        "\n",
        "# Load Best Model\n",
        "best = tf.keras.models.load_model(ckpt_path)\n",
        "\n",
        "val_gen_eval = val_datagen.flow_from_dataframe(\n",
        "    val_df, x_col='path', y_col='label_idx',\n",
        "    target_size=IMG_SIZE, class_mode='raw',\n",
        "    batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "preds_prob = best.predict(val_gen_eval, steps=val_steps, verbose=VERBOSE)\n",
        "preds = (preds_prob.ravel() > 0.5).astype(int)\n",
        "true = val_df['label_idx'].values[:len(preds)]\n",
        "\n",
        "acc  = accuracy_score(true, preds)\n",
        "prec = precision_score(true, preds, zero_division=0)\n",
        "rec  = recall_score(true, preds, zero_division=0)\n",
        "f1   = f1_score(true, preds, zero_division=0)\n",
        "\n",
        "print(f\"Fold {fold_no} -> acc:{acc:.4f}, prec:{prec:.4f}, rec:{rec:.4f}, f1:{f1:.4f}\")\n",
        "print(classification_report(true, preds, target_names=['benign','malignant'], zero_division=0))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(true, preds))\n",
        "\n",
        "# Visualization for this Fold\n",
        "plot_training_curves(history, fold_no)\n",
        "plot_confusion_matrix(true, preds, fold_no)\n",
        "plot_roc(true, preds_prob.ravel(), fold_no)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM5sliyJwWwW"
      },
      "source": [
        "##### Fold 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_Sga86HwaaM"
      },
      "outputs": [],
      "source": [
        "# Fold 3\n",
        "fold_no = 3\n",
        "\n",
        "# Data split\n",
        "train_idx, val_idx = splits[2]\n",
        "train_df = pd.DataFrame({'path': X[train_idx], 'label_idx': y[train_idx]})\n",
        "val_df   = pd.DataFrame({'path': X[val_idx],   'label_idx': y[val_idx]})\n",
        "\n",
        "class_weight = compute_weights(train_df['label_idx'].values)\n",
        "print(\"class_weight:\", class_weight)\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    train_df, x_col='path', y_col='label_idx',\n",
        "    target_size=IMG_SIZE, class_mode='raw',\n",
        "    batch_size=BATCH_SIZE, shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_dataframe(\n",
        "    val_df, x_col='path', y_col='label_idx',\n",
        "    target_size=IMG_SIZE, class_mode='raw',\n",
        "    batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "print_generator_info(train_gen, \"train_gen\")\n",
        "print_generator_info(val_gen, \"val_gen\")\n",
        "\n",
        "\n",
        "# Build Model\n",
        "model = build_resnet_binary(\n",
        "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "    unfreeze_last_n=40\n",
        ")\n",
        "\n",
        "\n",
        "# Callbacks\n",
        "ckpt_path = os.path.join(MODELS_DIR, f\"best_resnet_fold{fold_no}.keras\")\n",
        "csv_log_path = os.path.join(MODELS_DIR, f\"training_log_fold{fold_no}.csv\")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    CSVLogger(csv_log_path)\n",
        "]\n",
        "\n",
        "steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)\n",
        "val_steps = math.ceil(len(val_df) / BATCH_SIZE)\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=val_steps,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks,\n",
        "    verbose=VERBOSE\n",
        ")\n",
        "\n",
        "\n",
        "# Load Best Model\n",
        "best = tf.keras.models.load_model(ckpt_path)\n",
        "\n",
        "val_gen_eval = val_datagen.flow_from_dataframe(\n",
        "    val_df, x_col='path', y_col='label_idx',\n",
        "    target_size=IMG_SIZE, class_mode='raw',\n",
        "    batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "preds_prob = best.predict(val_gen_eval, steps=val_steps, verbose=VERBOSE)\n",
        "preds = (preds_prob.ravel() > 0.5).astype(int)\n",
        "true = val_df['label_idx'].values[:len(preds)]\n",
        "\n",
        "acc  = accuracy_score(true, preds)\n",
        "prec = precision_score(true, preds, zero_division=0)\n",
        "rec  = recall_score(true, preds, zero_division=0)\n",
        "f1   = f1_score(true, preds, zero_division=0)\n",
        "\n",
        "print(f\"Fold {fold_no} -> acc:{acc:.4f}, prec:{prec:.4f}, rec:{rec:.4f}, f1:{f1:.4f}\")\n",
        "print(classification_report(true, preds, target_names=['benign','malignant'], zero_division=0))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(true, preds))\n",
        "\n",
        "# Visualization for this Fold\n",
        "plot_training_curves(history, fold_no)\n",
        "plot_confusion_matrix(true, preds, fold_no)\n",
        "plot_roc(true, preds_prob.ravel(), fold_no)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzmU9P548MXe"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "n2jcLA2wDeW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2.2: Ensemble Model Construction and Evaluation**"
      ],
      "metadata": {
        "id": "dZozd3DoDjhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries & Path\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    roc_curve, auc, confusion_matrix, accuracy_score,\n",
        "    precision_score, recall_score, f1_score, classification_report\n",
        ")\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras import Input, Model\n",
        "import tensorflow as tf\n",
        "PLOTS_DIR = \"/content/drive/MyDrive/DermAI_plots\"\n",
        "MODELS_DIR = \"/content/drive/MyDrive/DermAI_models_resnet\"\n",
        "os.makedirs(PLOTS_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "9cwK89wDEpz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Fold Models\n",
        "fold_model_files = [\n",
        "    os.path.join(MODELS_DIR, \"best_resnet_fold1.keras\"),\n",
        "    os.path.join(MODELS_DIR, \"best_resnet_fold2.keras\"),\n",
        "    os.path.join(MODELS_DIR, \"best_resnet_fold3.keras\")\n",
        "]\n",
        "\n",
        "loaded_models = []\n",
        "for p in fold_model_files:\n",
        "    m = tf.keras.models.load_model(p)\n",
        "    m.trainable = False\n",
        "    loaded_models.append(m)"
      ],
      "metadata": {
        "id": "Pc2rPWNsDi10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Ensemble Model\n",
        "input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
        "ensemble_input = Input(shape=input_shape)\n",
        "\n",
        "outputs = [m(ensemble_input, training=False) for m in loaded_models]\n",
        "\n",
        "def average_preds(tensors):\n",
        "    stack = tf.stack(tensors, axis=0)\n",
        "    return tf.reduce_mean(stack, axis=0)\n",
        "\n",
        "avg = Lambda(average_preds)(outputs)\n",
        "\n",
        "ensemble_model = Model(inputs=ensemble_input, outputs=avg)\n",
        "\n",
        "ensemble_save_path = os.path.join(MODELS_DIR, \"ensemble_resnet_avg.keras\")\n",
        "ensemble_model.save(ensemble_save_path)\n",
        "ensemble_model"
      ],
      "metadata": {
        "id": "_Ca6kfdiFKZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot functions\n",
        "def save_confusion_matrix(true, preds, fold_no):\n",
        "    cm = confusion_matrix(true, preds)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Ensemble Confusion Matrix – Fold {fold_no}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    path = os.path.join(PLOTS_DIR, f\"ensemble_fold{fold_no}_cm.png\")\n",
        "    plt.savefig(path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def save_roc_curve(true, prob, fold_no):\n",
        "    fpr, tpr, _ = roc_curve(true, prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\")\n",
        "    plt.plot([0,1], [0,1], linestyle='--')\n",
        "    plt.title(f'Ensemble ROC Curve – Fold {fold_no}')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend()\n",
        "    path = os.path.join(PLOTS_DIR, f\"ensemble_fold{fold_no}_roc.png\")\n",
        "    plt.savefig(path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    return path"
      ],
      "metadata": {
        "id": "gIFhaLITFfEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Ensemble Across Folds\n",
        "ensemble_metrics = []\n",
        "threshold_results = []\n",
        "\n",
        "for fold_no, split in enumerate([splits[0], splits[1], splits[2]], start=1):\n",
        "    train_idx, val_idx = split\n",
        "    val_df = pd.DataFrame({'path': X[val_idx], 'label_idx': y[val_idx]})\n",
        "\n",
        "    val_gen_eval = val_datagen.flow_from_dataframe(\n",
        "        val_df, x_col='path', y_col='label_idx',\n",
        "        target_size=IMG_SIZE, class_mode='raw',\n",
        "        batch_size=16, shuffle=False,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    val_steps = int(np.ceil(len(val_df) / BATCH_SIZE))\n",
        "    preds_prob = ensemble_model.predict(val_gen_eval, steps=val_steps, verbose=0)\n",
        "    preds_prob = preds_prob.ravel()\n",
        "    true = val_df['label_idx'].values[:len(preds_prob)]\n",
        "\n",
        "    print(f\"\\nFold {fold_no}\")\n",
        "\n",
        "    # Evaluate threshold = 0.5\n",
        "    preds = (preds_prob > 0.5).astype(int)\n",
        "    acc  = accuracy_score(true, preds)\n",
        "    prec = precision_score(true, preds, zero_division=0)\n",
        "    rec  = recall_score(true, preds, zero_division=0)\n",
        "    f1   = f1_score(true, preds, zero_division=0)\n",
        "\n",
        "    ensemble_metrics.append({\n",
        "        'fold': fold_no,\n",
        "        'threshold': 0.5,\n",
        "        'accuracy': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1\n",
        "    })\n",
        "\n",
        "    print(\"Threshold = 0.50\")\n",
        "    print(f\"Acc={acc:.3f}, Prec={prec:.3f}, Rec={rec:.3f}, F1={f1:.3f}\")\n",
        "    print(classification_report(true, preds, target_names=['benign','malignant'], zero_division=0))\n",
        "\n",
        "    # Additional thresholds\n",
        "    for thresh in [0.35, 0.40, 0.45]:\n",
        "        preds_t = (preds_prob > thresh).astype(int)\n",
        "        acc_t  = accuracy_score(true, preds_t)\n",
        "        prec_t = precision_score(true, preds_t, zero_division=0)\n",
        "        rec_t  = recall_score(true, preds_t, zero_division=0)\n",
        "        f1_t   = f1_score(true, preds_t, zero_division=0)\n",
        "\n",
        "        threshold_results.append({\n",
        "            'fold': fold_no,\n",
        "            'threshold': thresh,\n",
        "            'accuracy': acc_t,\n",
        "            'precision': prec_t,\n",
        "            'recall': rec_t,\n",
        "            'f1': f1_t\n",
        "        })\n",
        "\n",
        "        print(f\"\\nThreshold = {thresh:.2f}\")\n",
        "        print(f\"Acc={acc_t:.3f}, Prec={prec_t:.3f}, Rec={rec_t:.3f}, F1={f1_t:.3f}\")"
      ],
      "metadata": {
        "id": "j7Pz4ikyFrnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "ensemble_df = pd.DataFrame(ensemble_metrics)\n",
        "threshold_df = pd.DataFrame(threshold_results)\n",
        "\n",
        "ensemble_df.to_csv(os.path.join(PLOTS_DIR, \"ensemble_results.csv\"), index=False)\n",
        "threshold_df.to_csv(os.path.join(PLOTS_DIR, \"threshold_results.csv\"), index=False)"
      ],
      "metadata": {
        "id": "mEIi1cUqF0rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate averages\n",
        "print(\"\\nAverage results:\")\n",
        "for thresh in [0.35, 0.40, 0.45, 0.50]:\n",
        "    if thresh == 0.50:\n",
        "        subset = ensemble_df\n",
        "    else:\n",
        "        subset = threshold_df[threshold_df['threshold'] == thresh]\n",
        "\n",
        "    print(f\"\\nThreshold {thresh:.2f}:\")\n",
        "    print(f\"  Acc={subset['accuracy'].mean():.3f}, Prec={subset['precision'].mean():.3f}, Rec={subset['recall'].mean():.3f}, F1={subset['f1'].mean():.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rZ_iY09wQEWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot 1: Thresholds comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "for i, metric in enumerate(['accuracy', 'precision', 'recall', 'f1']):\n",
        "    ax = axes[i//2, i%2]\n",
        "\n",
        "    # Average line\n",
        "    avgs = []\n",
        "    for thresh in [0.35, 0.40, 0.45, 0.50]:\n",
        "        if thresh == 0.50:\n",
        "            avgs.append(ensemble_df[metric].mean())\n",
        "        else:\n",
        "            avgs.append(threshold_df[threshold_df['threshold'] == thresh][metric].mean())\n",
        "\n",
        "    ax.plot([0.35, 0.40, 0.45, 0.50], avgs, marker='o', linewidth=2)\n",
        "    ax.set_xlabel('Threshold')\n",
        "    ax.set_ylabel(metric.capitalize())\n",
        "    ax.set_title(f'{metric.capitalize()} vs Threshold')\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOTS_DIR, 'threshold_comparison.png'), dpi=200)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UTDTcsq7Ox8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot 2: Individual vs Ensemble\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "individual = [0.8213, 0.7233, 0.7282, 0.7223]\n",
        "\n",
        "# Use threshold 0.40 results\n",
        "ensemble_040 = threshold_df[threshold_df['threshold'] == 0.40]\n",
        "ensemble_vals = [\n",
        "    ensemble_040['accuracy'].mean(),\n",
        "    ensemble_040['precision'].mean(),\n",
        "    ensemble_040['recall'].mean(),\n",
        "    ensemble_040['f1'].mean()\n",
        "]\n",
        "\n",
        "x = range(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "ax.bar([i - width/2 for i in x], individual, width, label='Individual', color='skyblue')\n",
        "ax.bar([i + width/2 for i in x], ensemble_vals, width, label='Ensemble (0.40)', color='blue')\n",
        "\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Individual vs Ensemble')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOTS_DIR, 'individual_vs_ensemble.png'), dpi=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mXLUOQ0bP7Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nPlots saved to {PLOTS_DIR}\")"
      ],
      "metadata": {
        "id": "QxCEZguRP-hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9nLmLYH9DhxG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-j18g1V8PQn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnxMPbhHho8d"
      },
      "source": [
        "## **Part Three: Results Analysis and Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Results Summary**"
      ],
      "metadata": {
        "id": "MpPfjysPWA0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DermAI training pipeline achieved consistent performance across the three validation folds.\n",
        "Results demonstrated stable accuracy, precision, recall, and F1-scores with low variance, indicating reliable generalization across different data splits.\n",
        "Performance metrics averaged around 83–84% accuracy, with balanced precision–recall behavior despite the dataset imbalance (≈ 13,294 benign vs. 6,211 malignant).\n",
        "\n",
        "The ensemble model, built by averaging predictions from the three fine-tuned ResNet models, provided a measurable improvement in probability stability and reduced fold-to-fold fluctuations, further supporting the robustness of the proposed approach."
      ],
      "metadata": {
        "id": "MudDRzFiWsUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xdr-ckB3WGQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Discussion & Analysis Resuls**\n",
        "\n"
      ],
      "metadata": {
        "id": "HLCqIyHeWKaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The obtained results demonstrate that the DermAI model maintains consistent classification performance across all three validation folds. The malignant class—being the minority—naturally exhibited lower recall relative to benign cases. However, the recall remained stable across folds (≈71–72%), indicating that the model did not collapse toward predicting the majority class.\n",
        "\n",
        "The use of class-weighted training played a noticeable role in maintaining balanced learning dynamics. Without class weights, the model would over-predict the benign class due to the dataset imbalance (approximately 2:1). Class weighting helped the network preserve sensitivity toward malignant samples without significantly compromising precision.\n",
        "\n",
        "Fine-tuning the last 40 layers of ResNet proved effective and allowed the model to learn subtle lesion-level patterns. The cross-fold ensemble additionally improved prediction smoothness and reduced misclassification variability by aggregating multiple model views of the same sample. Although the ensemble did not dramatically shift accuracy, its value lies in stabilizing probability outputs and making the final classifier less susceptible to the behavior of individual folds.\n",
        "\n",
        "Despite the improvements, malignant recall remains the most challenging metric. The difficulty is expected because malignant lesions exhibit high intra-class variability, and many benign lesions visually resemble early-stage malignancies. This overlap limits the separability of the two classes in feature space. Additional gains may require stronger preprocessing standardization, domain-specific data augmentation, or integrating metadata when clinically appropriate.\n",
        "\n",
        "Overall, the model demonstrates practical diagnostic potential. While not a replacement for clinical evaluation, its performance level aligns with several published dermatology-focused CNN approaches and shows clear ability to differentiate benign from malignant cases with reasonable reliability."
      ],
      "metadata": {
        "id": "-VqiFackW-KF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "s1FvkF94Wbfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Conclusion**"
      ],
      "metadata": {
        "id": "VD43J1sjWeSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DermAI achieved stable cross-validated performance with consistent generalization across folds. The combination of class-weighted fine-tuning and ensemble averaging contributed to balanced learning under dataset imbalance. While improving malignant recall remains a priority, the results indicate that the model performs at a level suitable for further refinement, integration into larger pipelines, and consideration for decision-support use cases."
      ],
      "metadata": {
        "id": "KrroZUYcXIPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vxXvKBTaWlJR"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_qb13R6y4OWW",
        "AvegU7jsUFOa",
        "dlNwr0kGmi-h",
        "dZozd3DoDjhX"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}